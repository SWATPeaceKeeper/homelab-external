# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Self-hosted homelab infrastructure on Hetzner Cloud (CX23, ~5 EUR/month). Provisioned via shell scripts (`bootstrap.sh` / `teardown.sh`) and Docker Compose. Documentation and comments are in German.

**Services:** Headscale v0.28.0 (VPN), Headplane 0.6.2 (VPN UI), Traefik v3.6.9 (reverse proxy + SSL), Uptime Kuma 2.1.3 (monitoring), ntfy v2.17.0 (push notifications), Healthchecks v4.0 (cron monitoring), Tailscale v1.94.2 (VPN client), two PostgreSQL 17.9-alpine databases.

## Architecture

### Provisioning

- **`bootstrap.sh`** — Creates everything: Hetzner server + firewall + SSH key, Cloudflare DNS records, clones repo, generates `.env`, starts Docker Compose, bootstraps Headscale. Requires `HCLOUD_TOKEN`, `CLOUDFLARE_API_TOKEN`, `CLOUDFLARE_ZONE_ID`. Uses `remote()` helper with `-i "$SSH_KEY_FILE"` and `UserKnownHostsFile=/dev/null` for all SSH commands.
- **`teardown.sh`** — Destroys everything: server, firewall, SSH key, DNS records. Requires "yes" confirmation.
- **`cloud-init.yaml`** — Static (no template variables). Base setup only: packages, Docker, UFW, fail2ban, directory structure, acme.json, cookie_secret, swap. YAML gotcha: shell commands with colons must use list syntax `['bash', '-c', '...']` to avoid YAML parsing errors.
- No Terraform, no CI/CD, no GitHub Secrets. All provisioning runs locally.

### Runtime Configuration

- **`hetzner/`** — Deployed to `/opt/homelab-repo/hetzner/` on the server. Docker Compose orchestrates all services. Config changes deployed manually (`git pull` on server, then `docker compose up -d`).

### Network Architecture

- **`proxy` network**: Services exposed via Traefik (headscale, headplane, uptime-kuma, ntfy, healthchecks)
- **`internal` network**: Database containers + services that need DB access (headscale-postgres, healthchecks-postgres, headscale, headplane, healthchecks)
- **host network**: Tailscale client (needs NET_ADMIN)
- Routing configured via Traefik Docker labels on each service

### Data Separation

- **Git repo configs** (read-only mounts): `./traefik/`, `./headscale/`, `./headplane/`
- **Persistent data** (on server, not in git): `/opt/homelab-data/<service>/`
- **Secrets**: `/opt/homelab-data/secrets/` (cookie_secret generated by Cloud-Init)

### Secrets Management

- Three env vars needed locally for provisioning: `HCLOUD_TOKEN`, `CLOUDFLARE_API_TOKEN`, `CLOUDFLARE_ZONE_ID`
- Runtime secrets in `hetzner/.env` (generated by `bootstrap.sh`, never committed)
- Headscale DB password: env var `HEADSCALE_DATABASE_POSTGRES_PASS` overrides config.yaml value
- Traefik dashboard: Basic Auth via `TRAEFIK_DASHBOARD_AUTH` in `.env` (htpasswd format, `$$` escaping)

## Commands

### Provisioning (local)

```bash
export HCLOUD_TOKEN=... CLOUDFLARE_API_TOKEN=... CLOUDFLARE_ZONE_ID=...
./bootstrap.sh    # Create everything (~3-5 min)
./teardown.sh     # Destroy everything (requires "yes" confirmation)
```

### Docker Compose (on server)

```bash
cd /opt/homelab-repo/hetzner
docker compose up -d
docker compose logs -f <service>
docker compose ps
docker compose pull && docker compose up -d   # Update images
```

### Service Admin (on server)

```bash
# Headscale
docker exec headscale headscale users list
docker exec headscale headscale preauthkeys create --user homelab --expiration 24h

# ntfy admin user
docker exec -it ntfy ntfy user add --role=admin admin

# Healthchecks superuser (set password via Web UI afterwards)
docker exec healthchecks ./manage.py createsuperuser --noinput --email admin@example.com
```

## Key Design Decisions

- No Terraform/CI/CD — shell scripts for simplicity, repo is public
- Cloudflare DNS records are `proxied = false` — required for Headscale DERP and WebSocket services
- Only IPv4 A-Records (no AAAA), 5 subdomains: headscale, uptime, ntfy, hc, traefik
- Cloud-Init does base setup only. Repo clone, .env, docker compose are done by `bootstrap.sh` via SSH
- `headscale-setup.sh` is idempotent (safe to run multiple times)
- Both PostgreSQL instances share the same `POSTGRES_PASSWORD` env var
- PostgreSQL volumes mount to `/var/lib/postgresql/data` (not `/var/lib/postgresql`)
- Headscale v0.28 uses Policy v2: user references require `@` suffix (e.g. `homelab@`, not `homelab`). Use `autogroup:member` for untagged devices, `tag:name` for tagged devices
- Headscale ACL SSH rules use `autogroup:member`/`autogroup:tagged` (wildcard `*` not supported in v0.28)
- Headscale v0.28 route CLI: `headscale nodes list-routes` and `headscale nodes approve-routes --identifier <ID> --routes <CIDR>` (old `headscale routes list/enable` removed in v0.26)
- Headscale DERP server needs explicit `private_key_path` in config
- Headscale postgres `ssl: false` (not `disable` — Headplane validator rejects `disable`)
- All Docker images pinned to specific versions. Renovate auto-updates with weekly schedule (patch automerge, minor/major as PR)
- Cron-based auto-deploy (Tuesday 12:00 UTC) pulls merged updates from main
- All containers run with no-new-privileges and cap_drop ALL
- Traefik enforces TLS 1.2+, security headers (HSTS, CSP), and rate limiting

## Known Pitfalls

- **Headplane version**: Must match Headscale version. v0.6.1 does NOT work with Headscale v0.28. Use v0.6.2+.
- **Headplane image tag**: NO `v` prefix on ghcr.io! Correct: `ghcr.io/tale/headplane:0.6.2` (not `v0.6.2`).
- **Headplane healthcheck**: Binary at `/bin/hp_healthcheck`. Unhealthy containers are invisible to Traefik (no routing).
- **Headplane Docker socket**: Config requires `unix:///var/run/docker.sock` prefix (not just the path).
- **Headplane Traefik routing**: Needs explicit `priority=200` so `/admin` paths go to Headplane, not the Headscale catch-all router.
- **Container capabilities**: `cap_drop: ALL` requires explicit `cap_add` for containers that manage files/permissions:
  - PostgreSQL: `CHOWN, DAC_OVERRIDE, FOWNER, SETGID, SETUID` (data directory init)
  - Headscale: `DAC_OVERRIDE, FOWNER, SETGID, SETUID` (runtime directory creation)
  - Uptime Kuma: `CHOWN, DAC_OVERRIDE, FOWNER, SETGID, SETUID` (embedded MariaDB)
  - Tailscale: `NET_ADMIN, SYS_MODULE` (VPN networking)
- **Healthchecks image**: No `curl`/`wget` available. Healthcheck uses Python `urllib` with Host header from `ALLOWED_HOSTS` env var (Django rejects `localhost` requests).
- **Uptime Kuma v2.x healthcheck**: Use `/api/entry-page` endpoint (not `/api/status-page/heartbeat` which returns 404).
- **Tailscale Docker networking**: Must set `TS_USERSPACE=false` for kernel networking mode. Default is userspace, which doesn't create kernel routes — other containers can't reach VPN subnets.
- **Tailscale subnet routing**: Hetzner Tailscale client needs `--accept-routes` to use subnet routes from the NUC. Without it, only `tailscale ping` works but no regular IP traffic.
- **Tailscale DNS (`--accept-dns`)**: The Hetzner Tailscale client uses `--accept-dns=false`. This setting persists in Tailscale state — removing the flag from `TS_EXTRA_ARGS` does NOT reset it, you must explicitly run `tailscale set --accept-dns=false`. Also: Tailscale in Docker with `network_mode: host` cannot configure systemd-resolved (no D-Bus access), so `--accept-dns=true` has no effect on host DNS.
- **Monitoring DNS for home network**: Uptime Kuma, Healthchecks, and ntfy use `dns: [10.10.10.3, 1.1.1.1]` in docker-compose.yml to resolve home network hostnames (e.g. `z2m.home.robinwerner.net`). Pi-hole (10.10.10.3) as primary, Cloudflare as fallback. Requires port 53 in ACL for `tag:server` → `homelab-network`.
- **Headscale ACL port 53**: The ACL must include `homelab-network:53` for `tag:server` so DNS queries from monitoring containers can reach Pi-hole via VPN.
- **SSH key**: Located at `~/.ssh/homelab-external` (not `~/.ssh/id_ed25519`). Use with `-i ~/.ssh/homelab-external`.
- **SSH known_hosts**: `bootstrap.sh` uses `UserKnownHostsFile=/dev/null` because server IPs get reused after teardown/rebuild.
- **Cloud-init YAML**: Colons in shell commands break YAML parsing. Use list syntax: `['bash', '-c', 'echo "done: $(date)"']`.

## Repo Structure

```
bootstrap.sh          # Provisioning script (local)
teardown.sh           # Teardown script (local)
cloud-init.yaml       # Server base setup (static, no templates)
README.md             # Project overview (short, links to docs/)
renovate.json         # Renovate auto-update config
CLAUDE.md             # This file
docs/
  README.md           # Detailed project documentation
  SETUP.md            # Setup guide
  plans/              # Design documents
hetzner/
  .env.example        # Environment template
  docker-compose.yml  # All services
  scripts/
    headscale-setup.sh  # Headscale bootstrap (runs on server)
    auto-update.sh      # Cron-based auto-deploy script
  headplane/
    config.yaml
  headscale/
    acl.json
    config.yaml
    dns_records.json  # Extra DNS records (empty template)
  traefik/
    traefik.yml
```
